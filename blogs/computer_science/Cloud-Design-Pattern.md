Cloud Design Patterns
==========================

[原文](https://msdn.microsoft.com/en-us/library/dn568099.aspx)


[TOC]

## Cache-Aside 模式

**Read:**

> 1. 检查数据当前是否在缓存中
> 2. 如果数据不在缓存中, 则从数据库读取
> 3. 将数据的拷贝保存在缓存中

**Write: **

> 1. 如果数据不在缓存中,  直接写到数据库
> 2. 如果数据在缓存中, 则删除缓存中的数据拷贝.

#### 注意:

* 缓存生命周期: 通常缓存数据会设置过期时间, 过长过短都会有问题. 缓存时间需要根据应用的数据访问模型来进行设置. 另外要注意, 缓存只在相对静态的数据或读显著高于写的情景下才能提高效率.
* 数据的淘汰(Evicting): 当缓存快满时, 需要将一些数据干掉以释放空间, 通常使用LRU算法, 也可以根据自己业务来自定义算法. 注意淘汰数据的时候最好综合考虑从数据库读取数据的成本和保留缓存数据的成本以及处理淘汰策略的成本.
* 预热(Priming): 在应用启动时将可能会访问到的数据提前加载到缓存, 以避免启动时服务和数据库的过载.
* 一致性风险: 虽然应用内的代码会尽量处理好一致性问题, 但难免出现遗漏, 以及从其他程序对数据库的修改. 尤其是当复制库之间进行频繁同步的时候, 可能会导致难以理解的一致性问题.
* 本地缓存: 使用本机内存作为缓存会在集群环境下带来一些不便. 不同节点间的缓存数据会快速出现大量不一致. 对数据快速过期只能缓解症状.

#### 使用场景:

数据分布在一个较大的范围内(无法完全载入缓存), 并且实际数据需求难以预测, 因此将数据向缓存的加载推迟到数据将要被使用时.
另外要注意, 对于web应用的会话信息不适用该模式.


## Circuit Breaker 模式

该模式用于在访问远端数据或服务时出现的临时性的失败或异常时进行控制.

简单使用 retry 反而会使得系统资源被迅速耗尽, 直至崩溃. 此时旧需要这种断路器模式了.

该模式的本质是个状态机, 来模拟电路中的断路器. 它具有三种状态:

* Closed: 闭合状态. 此时正常请求, 如果出现错误则记录次数, 当一段时间内的错误率达到一定阈值, 则变为 Open 状态, 同时启动一个 timeout 定时器, 当定时器结束后状态将自动变为 Half-Open 状态.

* Open: 此时会立刻返回收到的请求, 而不再执行请求对应的操作.

* Half-Open: 这种状态下会尝试以限定的速度(次数)来执行操作并响应请求, 如果这些操作都成功, 则变为 Closed 状态并重置 failure 计数器, 此时服务恢复; 如果其中任何一个失败, 则再次将状态变为 Open 并设置新的 timeout 计时器.

通过合理设置 Half-Open 状态, 可以避免故障恢复后出现瞬间负载过高导致再次超时或故障.  当 Half-Open 状态再次转为 Open 状态时, 也可以逐步增加 timeout 计时器的时间.  实践中 Open 状态可以返回异常, 也可以返回一个有意义的默认值.


#### 注意:

* 对于比较复杂的情况, 可以根据失败时的不同异常类型来进行不同程度的处理.
* 注意控制计时器的时间, 太长会导致故障恢复后无法尽快转换状态, 太短会导致频繁在 Open 和 Half-Open 状态之间切换.
* 可以在 Open 状态下使用心跳检测或 ping 的方式来帮助尽早探测到服务的恢复, 以减少等待时间.
* 对于可能会故障很久的情况, 采用管理员手动切换状态的方式也是一个办法.
* 很多情况下, 断路器都需要应付高并发的场景, 请确保断路器实现能正确处理并发请求, 另外, 注意不要引入过高的性能开销.
* 注意远端不同数据源的区别对待, 以免混淆. 比如数据库的不同 replication.
* 某些情况下可以记录 Open 状态时的请求, 当状态正常后再重放这些请求.



## Compensating Transaction 模式

不知道是不是可以翻译成事务补偿模式.

应用所依赖并需要修改的数据通常并不在一个位置, 他们分布在不同的数据库, 机器, 机房, 城市. 实践中, 在这样的情况下去保证事务一致性是低效且不可取的. 事实上应该去保证最终一致性而不是事务一致性.

一系列相关操作的回滚不是简单的将数据恢复到操作之前, 而是需要考虑到在这期间的其他并发操作的影响, 考虑到各个步骤间可能完全异构的数据持久化方式, 考虑服务本身状态变化的回滚等许多复杂因素.

一般可以使用 workflow 的方式实现最终一致性操作. 记录每一步操作, 并且每一个步骤都有对应的撤销操作.     多个步骤的撤销操作有可能是同时进行, 并不一定是按照正向操作完全相反的顺序进行.

Compensating Transaction 本身也有可能会失败. 系统应该能够从未完全执行的"事务"中进行恢复并继续执行. 这个过程中有可能需要重复执行上次失败的操作, 因此, 最好将所有的操作都设计为 idempotency (幂等)的. 另外有时可能某些异常或失败需要人工干预, 这时应该尽量保留关键业务中尽可能的各种信息以备审阅.

#### 注意:

* 有时候, 某个有问题的步骤并没有立即返回失败, 而是被阻塞了. 这个时候需要用超时机制来解决.
* 补偿逻辑都是强业务相关的, 因此它以赖于步骤执行中是否可以提供充分的信息用来进行操作的撤销.
* 执行事务逻辑的部分需要能快速从故障中恢复, 并完整的保留上次处理时的断点信息, 用来从故障中准确的恢复事务的处理.
* 对于一次操作中所要使用的所有数据加一个时间较短的超时锁, 并在操作开始前先获取他们, 这样可以提高整体的操作成功率. 操作必须在获取到本次执行所需的所有数据后才开始, 必须在超时锁到期前结束才算完成.
* 可以与重试模式结合, 在操作 fail 或异常后先重试, 再重试无法完成的情况下在进行事务的撤销.


## Compensating Transaction 模式


1. 多应用程序(生产者)接收用户的请求, 将其封装为消息, 送到消息队列中.
2. 多个后台服务程序(消费者)从队列中读取消息, 并对其进行处理.

#### 作用与优点

* 用于处理大量的请求(异步地), 业务逻辑处理过程中, 不会阻塞其他请求的处理.
* 可以应付突发的大量请求, 消息队列可以作为一个 buffer.
* 提高了服务的整体可靠性.
* 消费者之间不需要太复杂的协调处理
* 可扩展性, 易扩展性
* 消息队列可以改造成支持事务的方式, 当消费者处理失败后可以重新放入队列被其他实例处理.

#### 注意

1. 需要注意负载的均衡性, 以免个别实例成为系统瓶颈
2. 恰当处理消息的顺序. 将消息设计成具有幂等性质的, 以消除系统对消息的顺序的依赖.
3. 需要检测并处理有问题的消息. 以免出现循环重试.
4. 如果后台服务(消费者)完成了对消息的处理并生成了结果, 并且需要将这个结果返回给应用程序(生产者). 那么需要将结果保存在一个地方(可以被应用程序访问到), 并设法通知应用程序该消息已处理完成, 让它去指定位置取出结果即可.
5. 当系统规模很大时, 单个消息队列会成为瓶颈. 可以考虑将生产者和消费者分成多个区, 每个区有一个消息队列, 也可以不分区, 而采用负载均衡的方式向多个消息队列分发消息.
6. 消息队列本身需要保证可靠性, 即所有收到的消息至少需要被发送一次.

#### 使用场景

1. 业务逻辑可以被拆分成若干可异步执行的任务.
2. 任务之间无依赖, 可以并行执行

PS:

**PeekLock** : 也称非破坏性读. 从消息队列读取消息时并不直接删除, 而仅将它对其他消费者隐藏. 首个消费者如果成功处理完成该消息, 会主动将它送消息队列中删除, 如果失败, 则 peeklock 会超时, 并将该消息重新置为可见状态.







##Compute Resource Consolidation 模式

有时针对一个应用或服务, 我们会将其中的每个小的计算过程拆分成独立的计算单元, 这样可以简化复杂业务逻辑的设计, 但是同时也增加了整个系统的运行开销可复杂度.

通过将多个计算单元合并起来, 可以降低开销, 提高利用率和通信速度, 并且易于管理.

可合并性:  可以从几个方面考虑.  1. 关于可扩展性相关的配置(如需要配置的实例个数等),  2. 运算生命周期,  3. 运算所需资源.

不适合合并的情况, 比如下面两个任务: 1. 轮询, 对时间敏感的消息发送服务; 2. 处理大量突发网络请求的服务.  体会一下他们两之间的差异.

关于生命周期:  在云上的服务设施可能会周期性的进行回收处理. 对于一些服务我们可能需要设置一些检查点, 使得当程序下次启动时可以从检查点的位置继续执行.

发布节奏: 某些计算可能会频繁发布新的代码, 这些发布导致的代码更新, build, 部署等操作同样会影响到与其合并在一起的其他计算任务.

容错: 合并在一起的计算任务, 如果一个出了问题就很可能会影响到另一个的正常执行.

资源竞争: 合并在一起的计算单元最好有着互补的资源需求, 以免发生对资源(CPU, 内存, IO等)的大量竞争.

#### 不适用的场景

* 关键的容错服务
* 具有高敏感性或私有数据的服务
* 具有独立安全配置的服务

## Command and Query Responsibility Segregation (CQRS) 模式

命令与查询职责分离, 其实也相当与是一种读写分离.

传统的方式: 针对一类数据实体, 存在对应的数据传输对象(DTO), 对该数据的读和写都由 DTO 负责和控制. 对于小规模的简单逻辑, 这样的方式还可以胜任, 但当业务逻辑越来越复杂后, 开发维护成本, 以及潜在的安全风险和数据不一致性, 以及整体性能都会收到很大影响.

使用 CQRS 模式的方式: 针对一类数据实体, 读写操作分为两个不同的接口. 这样可以简化设计和实现方式, 但缺点是这种方式可能无法使用工具自动生成代码 (比如 JAVA ).

读和写通常可以操作同一个物理上的数据存储设备, 但也可以通过使用不同的物理数据层来提高性能 (比如 mongodb 的 secondary replication). 通过使用多个只读的数据层可以显著提高查询性能和应用程序的响应速度. 分离读写部分, 还有利于进行根具针对性的扩展来满足业务需求, 比如通常查询请求的量要明显高于写入/修改请求.

**关注点:**

* 将数据存储在不同物理节点可以提高性能, 但代价是系统的复原性和最终一致性所带来的复杂度的上升.
* 实现最终一致性的一种典型的方式是使用事件驱动来连接 CQRS. 写入模块是一个由事件驱动的, 只能追加的流. 所执行的指令用来更新读取模块的视图(view).

当联合 CQRS 和事件驱动一起使用:

* 这种模式下, 仅能保证最终一致性. 在事件发生到数据最终被更新之间会存在一定的延迟.
* 事件驱动会引入一定的复杂度来发出和处理事件等. CQRS 本身具有的复杂度和事件驱动模式结合后, 将使实现更加困难. 但事件驱动也带来了好处: 1, 更容易对一块业务进行建模; 2, 更容易对视图进行重建, 或直接重新生成一个. 因为将要变化的信息被保留在事件对应的数据中.
* 需要留意数据处理所需的时间以及占用的资源. 因为所有相关的事件都需要被检查. 通过实现一个周期性的数据快照可以解决一部分这类问题.





## Event Sourcing Pattern

append-only 的事件队列, 其中的事件描述了在针对一个 domain 中的数据进行的操作而不是数据的当前状态.

可以简化任务的复杂度, 避免对同步任务 model 的依赖, 还能提升性能, 扩展性,  响应速度, 提供数据一致性. 提供审计的线索, 并且支持进行补偿(compensate)操作.

传统 CRUD 的局限性:

* 直接在数据存储上进行更新操作, 影响性能, 响应速度, 限制了扩展性.
* 在多用户并发场景下会出现大量的冲突.
* 无法进行数据操作的审计, 除非单独开发数据操作记录功能.

**解决方案: **
将对数据的操作描述封装成事件, 事件有序的插入处理队列中, 该队列也同时在存储设备上进行持久化. 这些事件本身就可以用于审计.
事件存储器同时也负责向对应的处理器发布这些事件,  这些事件的发布可以复制成多份, 发送给不同的服务.
注意, 应用程序中生成事件的部分, 和后端对事件进行处理的部分是接耦的.

典型的使用场景是用于维护某些数据实体的物化视图(materialized view). 当某个动作发生的时候, 该事件消息被发布到多个 handler 中, 对与这个动作影响的数据有关联的其他数据作出修改. 这些修改和动作本体接耦.

**事件驱动的优点**

* 事件本身是不可变的对象, 因此可以用 append-only 的方式存储. UI, 工作流等进程生成并发出对应的事件后就可以继续向下执行了, 而操作的执行由后端的程序执行. 每个事务的执行之间不会存在竞争. 消除了事务之间的竞争, 将会大幅提高系统的性能以及可扩展性. 尤其是对于会话层和 UI 层.
* 事件对象中的结构较简单, 主要包含对操作的描述和与操作相关的一些额外数据. 这些都相对比较易于实现和管理.
* 事件对象对于领域内专业人士是有意义的, 但数据库里的数据可能对他们就没有可读性了.
* 可以防止并发更新造成的冲突. 不过模型本身也需要在设计上防止读到不一致的数据才行.
* 方便审计, 数据状态的还原, 重放, 以及测试和调试. 并且可以方便的撤销数据的变更到任意历史位置.
* 解耦!

⧸⧸关注点: ⧸⧸**关注点:**⧸⧸

* 存储的事件是不可变的. 如果需要撤销修改, 也是通过发送互补事件来完成(相当于反向事务).  有不可变性带来的一个问题是, 当事件的格式更新的时候, 事件的存储器中会同时存在新旧两种不同格式的事件. 处理器需要能够同时应付二者, 因此, 事件信息中带有 version 信息就是一个比较好的策略了.
* 多线程或多实例应用使用事件驱动时, 事件存储的一致性问题非常重要. 不同事件间的顺序可能对结果有很大影响. 给事件添加时间戳可以一定程度上缓解事件顺序带来的问题.  另外也可以在事件中使用数据ID和事件ID, 当出现操作的冲突时, 可以根据ID拒绝某个事件的操作.
* 可以每隔一段时间(比如一小时)就给数据做一个快照, 每个时间间隔将事件流分成若干段. 这样就可以从任意快照获取当时的数据状态, 并且重放其前后的事件流就可以将数据状态拨到指定的时间点.
* 事件流可以缓解数据操作冲突的可能性, 但无法完全避免这种问题. 对于一些边界情况依然需要有对应的策略进行处理.
* 事件信息通常只能保证 "至少发送一次". 因此事件本身需要设计成幂等的. 需要避免同一事件被播放两次造成的错误操作.

#### 使用场景

适用:

* 需要知道每一次数据修改的目的或原因的场景
* 需要减少甚至避免数据更新冲突的场景
* 需要通过重放事件进行数据恢复或撤销的场景

不适用:

* 太小, 业务逻辑太简单的系统.
* 对数据一致性和数据的实时处理有严格要求的场景
* 对数据历史, 审计, 回滚重放等没有需求的场景
* 几乎不会发生数据更新冲突的场景.

## External Configuration Store Pattern

将应用程序的配置文件从构建的包中转移到一个中心化管理的地方. 用于简化应用的配置管理以及赋予灵活的控制能力.

配置信息置于包中, 每次修改都需要重新部署. 不同应用之间也无法共享一些配置, 比如数据库url, UI主题等.

实现外部存储保存配置信息, 保证其接口可以简单高效的读写配置信息.  配置信息的保存应该是带类型并且格式化的(比如 json 或 yaml). 多数情况下该接口可能需要实现认证授权的功能来保护其中的配置信息.  最后, 需要支持多版本的配置信息, 用于 dev, staging, production 等可能的环境中.


如何处理配置信息的作用域问题, 以及配置之间的继承属性的设置(不同级别如公司, 应用, 实例等之间会有一些配置的继承或扩展关系).

配置信息健壮性的问题, 无法读取? 写入错误的数据? 字符大小写? 二进制数据的处理? null 和空字符串的处理?



## Federated Identity Pattern

将身份验证代理给外部的 ID 系统.

类似于单点登录, OAuth.



## Health Endpoint Monitoring Pattern


